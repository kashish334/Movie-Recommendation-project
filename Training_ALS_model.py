# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IrpAOkil-V7tK4jbzzdE1YqmNP2flOuP
"""

from pyspark.sql import SparkSession
from pyspark.ml.recommendation import ALS
from pyspark.ml.evaluation import RegressionEvaluator
from pyspark.sql.functions import explode, col
from pyspark.sql import SparkSession
import os
import pickle
import numpy as np

# Create Spark session (Driver only)
def create_spark():
    spark = SparkSession.builder \
        .appName('rec') \
        .master('local[*]') \
        .config("spark.driver.memory", "6g") \
        .config("spark.driver.maxResultSize", "4g") \
        .config("spark.executor.memory", "6g") \
        .config("spark.sql.adaptive.enabled", "true") \
        .config("spark.sql.adaptive.coalescePartitions.enabled", "true") \
        .getOrCreate()
    
    return spark

# Train ALS Collaborative Filtering Model
def train_ALS():

    spark = create_spark()
    ratings = spark.read.csv("data/ratings.csv", header=True, inferSchema=True)
    movies = spark.read.csv("data/movies.csv", header=True, inferSchema=True)

    # Cast columns to required data types
    ratings = ratings.withColumn("userId", col("userId").cast("integer")) \
        .withColumn("movieId", col("movieId").cast("integer")) \
        .withColumn("rating", col("rating").cast("float"))

    (train, test) = ratings.randomSplit([0.8, 0.2], seed=42)
    train.cache()
    test.cache()
    als = ALS(
        userCol="userId", 
        itemCol="movieId", 
        ratingCol="rating", 
        coldStartStrategy="drop", 
        nonnegative=True, # Non-negative constraints
        rank=8,       # Latent factors  
        maxIter=10,   # Number of iterations
        regParam=0.1,  # Regularization
        numUserBlocks=10,    # Parallelism tuning
        numItemBlocks=10   
    )
    model = als.fit(train)

    item_factors = model.itemFactors.toPandas()
    item_ids = item_factors['id'].values
    item_factors = np.array(item_factors['features'].to_list(), dtype=float)
    item_factors_dict = dict(zip(item_ids, item_factors))
    with open('item_factors.pkl', 'wb') as f:
        pickle.dump(item_factors_dict, f)

    predictions = model.transform(test)

    evaluator = RegressionEvaluator(
        metricName="rmse",
        labelCol="rating",
        predictionCol="prediction"
    )

    rmse = evaluator.evaluate(predictions)
    print(f"Root-mean-square error = {rmse}")

    # Generate Top-N recommendations per user
    user_recs = model.recommendForAllUsers(5)

    # Explode nested recommendation structure
    df_exploded = user_recs.select("*", explode("recommendations").alias("rec"))

    # Extract movieId and predicted rating
    df_split = df_exploded.select("userId", "recommendations", col("rec.movieId").alias("movieId"), col("rec.rating").alias("rating"))

    # Join with movie titles
    df_titles = df_split.join(movies.select("movieId", "title"), on="movieId", how="left")
    df_titles_pd = df_titles.toPandas()
    os.makedirs("artifacts", exist_ok=True)

    df_titles_pd.to_csv(
        "artifacts/movies_rec_user.csv",
        index=False,
        encoding="utf-8"
        )  
    
if __name__ == "__main__":
    train_ALS()